# Breeze Configuration Example
# Copy this file to .env and update with your values

# Embedding Model Configuration
# For local models (default):
BREEZE_EMBEDDING_MODEL=ibm-granite/granite-embedding-125m-english
BREEZE_EMBEDDING_DEVICE=cpu  # Options: cpu, cuda, mps (auto-detects if not set)

# For Voyage AI models:
# BREEZE_EMBEDDING_MODEL=voyage-code-3
# BREEZE_EMBEDDING_API_KEY=your-voyage-api-key-here
# BREEZE_VOYAGE_TIER=1  # Options: 1, 2, or 3 (see rate limits below)
# BREEZE_VOYAGE_CONCURRENT_REQUESTS=5  # Auto-calculated based on tier if not set

# Voyage AI Tier Rate Limits:
# Tier 1: 3M tokens/min, 2000 requests/min
# Tier 2: 6M tokens/min, 4000 requests/min (2x base)
# Tier 3: 9M tokens/min, 6000 requests/min (3x base)

# For Google Gemini models:
# BREEZE_EMBEDDING_MODEL=models/text-embedding-004
# BREEZE_EMBEDDING_API_KEY=your-google-api-key-here

# Concurrency Settings
BREEZE_CONCURRENT_READERS=20
BREEZE_CONCURRENT_EMBEDDERS=10
BREEZE_CONCURRENT_WRITERS=10

# Server Settings
BREEZE_HOST=127.0.0.1
BREEZE_PORT=9483

# Debug Settings
# BREEZE_DEBUG_LANCE=1  # Enable LanceDB debug logging